{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"OpenAI Function Call","text":"<p>OpenAISchema, structured extraction in Python, powered by OpenAI, designed for simplicity, transparency, and control.</p> <p>This library is build to interact with openai's function call api from python code, with python objects. It's designed to be intuitive, easy to use, but give great visibily in how we call openai.</p> <p>The approach of combining a human prompt and a \"response schema\" is not necessarily unique; however, it shows great promise. As we have been concentrating on translating user intent into structured data, we have discovered that Python with Pydantic is exceptionally well-suited for this task. </p> <p>OpenAISchema is based on Python type annotations, and powered by Pydantic.</p> <p>The key features are:</p> <ul> <li>Intuitive to write: Great support for editors, completions. Spend less time debugging.</li> <li>Writing prompts as code: Collocate docstrings and descriptions as part of your prompting.</li> <li>Extensible: Bring your own kitchen sink without being weighted down by abstractions.</li> </ul>"},{"location":"#structured-extraction-with-openai","title":"Structured Extraction with <code>openai</code>","text":"<p>Welcome to the Quick Start Guide for OpenAI Function Call. This guide will walk you through the installation process and provide examples demonstrating the usage of function calls and schemas with OpenAI and Pydantic.</p>"},{"location":"#requirements","title":"Requirements","text":"<p>This library depends on Pydantic an OpenAI that's all.</p>"},{"location":"#installation","title":"Installation","text":"<p>To get started with OpenAI Function Call, you need to install it using <code>pip</code>. Run the following command in your terminal:</p> <p>Note</p> <p>Ensure you have Python version 3.9 or above.</p> <pre><code>$ pip install openai_function_call\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<p>This quick start guide contains the follow sections:</p> <ol> <li>Defining a schema </li> <li>Adding Additional Prompting</li> <li>Calling the ChatCompletion</li> <li>Deserializing back to the instance</li> </ol> <p>OpenAI Function Call allows you to leverage OpenAI's powerful language models for function calls and schema extraction. This guide provides a quick start for using OpenAI Function Call.</p>"},{"location":"#section-1-defining-a-schema","title":"Section 1: Defining a Schema","text":"<p>To begin, let's define a schema using OpenAI Function Call. A schema describes the structure of the input and output data for a function. In this example, we'll define a simple schema for a <code>User</code> object:</p> <pre><code>from openai_function_call import OpenAISchema\nclass UserDetails(OpenAISchema):\nname: str\nage: int\n</code></pre> <p>In this schema, we define a <code>UserDetails</code> class that extends <code>OpenAISchema</code>. We declare two fields, <code>name</code> and <code>age</code>, of type <code>str</code> and <code>int</code> respectively. </p>"},{"location":"#section-2-adding-additional-prompting","title":"Section 2: Adding Additional Prompting","text":"<p>To enhance the performance of the OpenAI language model, you can add additional prompting in the form of docstrings and field descriptions. They can provide context and guide the model on how to process the data.</p> <pre><code>from openai_function_call import OpenAISchema\nfrom pydantic import Field\nclass UserDetails(OpenAISchema):\n\"Correctly extracted user information\"\nname: str = Field(..., description=\"User's full name\")\nage: int\n</code></pre> <p>In this updated schema, we use the <code>Field</code> class from <code>pydantic</code> to add descriptions to the <code>name</code> field. The description provides information about the field, giving even more context to the language model.</p> <p>Code, schema, and prompt</p> <p>We can run <code>openai_schema</code> to see exactly what the API will see, notice how the docstrings, attributes, types, and field descriptions are now part of the schema. This describes on this library's core philosophies.</p> <pre><code>class UserDetails(OpenAISchema):\n\"Correctly extracted user information\"\nname: str = Field(..., description=\"User's full name\")\nage: int\nUserDetails.openai_schema\n</code></pre> <pre><code>{\n\"name\": \"UserDetails\",\n\"description\": \"Correctly extracted user information\",\n\"parameters\": {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\n\"description\": \"User's full name\",\n\"type\": \"string\"\n},\n\"age\": {\n\"type\": \"integer\"\n}\n},\n\"required\": [\n\"age\",\n\"name\"\n]\n}\n}\n</code></pre>"},{"location":"#section-3-calling-the-chatcompletion","title":"Section 3: Calling the ChatCompletion","text":"<p>With the schema defined, let's proceed with calling the <code>ChatCompletion</code> API using the defined schema and messages.</p> <pre><code>from openai_function_call import OpenAISchema\nfrom pydantic import Field\nclass UserDetails(OpenAISchema):\n\"Correctly extracted user information\"\nname: str = Field(..., description=\"User's full name\")\nage: int\ncompletion = openai.ChatCompletion.create(\nmodel=\"gpt-3.5-turbo-0613\",\nfunctions=[UserDetails.openai_schema],\nfunction_call={\"name\": UserDetails.openai_schema[\"name\"]},\nmessages=[\n{\"role\": \"system\", \"content\": \"Extract user details from my requests\"},\n{\"role\": \"user\", \"content\": \"My name is John Doe and I'm 30 years old.\"},\n],\n)\n</code></pre> <p>In this example, we make a call to the <code>ChatCompletion</code> API by providing the model name (<code>gpt-3.5-turbo-0613</code>) and a list of messages. The messages consist of a system message and a user message. The system message sets the context by requesting user details, while the user message provides the input with the user's name and age.</p> <p>Note that we have omitted the additional parameters that can be included in the API request, such as <code>temperature</code>, <code>max_tokens</code>, and <code>n</code>. These parameters can be customized according to your requirements.</p>"},{"location":"#section-4-deserializing-back-to-the-instance","title":"Section 4: Deserializing Back to the Instance","text":"<p>To deserialize the response from the <code>ChatCompletion</code> API back into an instance of the <code>UserDetails</code> class, we can use the <code>from_response</code> method.</p> <pre><code>user = UserDetails.from_response(completion)\nprint(user.name)  # Output: John Doe\nprint(user.age)   # Output: 30\n</code></pre> <p>By calling <code>UserDetails.from_response</code>, we create an instance of the <code>UserDetails</code> class using the response from the API call. Subsequently, we can access the extracted user details through the <code>name</code> and <code>age</code> attributes of the <code>user</code> object.</p>"},{"location":"#ide-support","title":"IDE Support","text":"<p>Everything is designed for you to get the best developer experience possible, with the best editor support.</p> <p>Including autocompletion:</p> <p></p> <p>And even inline errors</p> <p></p>"},{"location":"#openai-schema-and-pydantic","title":"OpenAI Schema and Pydantic","text":"<p>This quick start guide provided you with a basic understanding of how to use OpenAI Function Call for schema extraction and function calls. You can now explore more advanced use cases and creative applications of this library.</p> <p>Since <code>UserDetails</code> is a <code>OpenAISchems</code> and a <code>pydantic.BaseModel</code> you can use inheritance and nesting to create more complex emails while avoiding code duplication</p> <pre><code>class UserDetails(OpenAISchema):\nname: str = Field(..., description=\"User's full name\")\nage: int\nclass UserWithAddress(UserDetails):\naddress: str \nclass UserWithFriends(UserDetails):\nbest_friend: UserDetails\nfriends: List[UserDetails]\n</code></pre> <p>If you have any questions, feel free to leave an issue or reach out to the library's author on Twitter. For a more comprehensive solution with additional features, consider checking out MarvinAI.</p> <p>To see more examples of how we can create interesting models check out some examples.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under ther terms of the MIT License.</p>"},{"location":"api_multitask/","title":"API: MultiTask","text":""},{"location":"api_multitask/#openai_function_call.dsl.multitask.MultiTask","title":"<code>MultiTask(subtask_class, name=None, description=None)</code>","text":"<p>Dynamically create a MultiTask OpenAISchema that can be used to segment multiple tasks given a base class. This creates class that can be used to create a toolkit for a specific task, names and descriptions are automatically generated. However they can be overridden.</p> Note <p>Using this function is equivalent to creating a class that inherits from OpenAISchema and has a list of the subtask class as a field.</p> <pre><code>class MultiTask(OpenAISchema):\n\"\"\"\n    Correct segmentation of `{subtask_class.__name__}` tasks\n    \"\"\"\ntasks: List[subtask_class] = Field(\ndefault_factory=list,\nrepr=False,\ndescription=f\"Correctly segmented list of `{subtask_class.__name__}` tasks\",\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>subtask_class</code> <code>Type[OpenAISchema]</code> <p>The base class to use for the MultiTask</p> required <code>name</code> <code>Optional[str]</code> <p>The name of the MultiTask class, if None then the name of the subtask class is used as <code>Multi{subtask_class.__name__}</code></p> <code>None</code> <code>description</code> <code>Optional[str]</code> <p>The description of the MultiTask class, if None then the description is set to <code>Correct segmentation of</code>{subtask_class.name}<code>tasks</code></p> <code>None</code> <p>Returns:</p> Name Type Description <code>schema</code> <code>OpenAISchema</code> <p>A new class that can be used to segment multiple tasks</p> Source code in <code>openai_function_call/dsl/multitask.py</code> <pre><code>def MultiTask(\nsubtask_class: Type[BaseModel],\nname: Optional[str] = None,\ndescription: Optional[str] = None,\n):\n\"\"\"\n    Dynamically create a MultiTask OpenAISchema that can be used to segment multiple\n    tasks given a base class. This creates class that can be used to create a toolkit\n    for a specific task, names and descriptions are automatically generated. However\n    they can be overridden.\n    Note:\n        Using this function is equivalent to creating a class that inherits from\n        OpenAISchema and has a list of the subtask class as a field.\n        ```python\n        class MultiTask(OpenAISchema):\n            \\\"\"\"\nCorrect segmentation of `{subtask_class.__name__}` tasks\n            \\\"\"\"\n            tasks: List[subtask_class] = Field(\n                default_factory=list,\n                repr=False,\n                description=f\"Correctly segmented list of `{subtask_class.__name__}` tasks\",\n            )\n        ```\n    Parameters:\n        subtask_class (Type[OpenAISchema]): The base class to use for the MultiTask\n        name (Optional[str]): The name of the MultiTask class, if None then the name\n            of the subtask class is used as `Multi{subtask_class.__name__}`\n        description (Optional[str]): The description of the MultiTask class, if None\n            then the description is set to `Correct segmentation of `{subtask_class.__name__}` tasks`\n    Returns:\n        schema (OpenAISchema): A new class that can be used to segment multiple tasks\n    \"\"\"\ntask_name = subtask_class.__name__ if name is None else name\nname = f\"Multi{task_name}\"\nlist_tasks = (\nList[subtask_class],\nField(\ndefault_factory=list,\nrepr=False,\ndescription=f\"Correctly segmented list of `{task_name}` tasks\",\n),\n)\nnew_cls = create_model(\nname,\ntasks=list_tasks,\n__base__=(OpenAISchema, MultiTaskBase),\n)\n# set the class constructor BaseModel\nnew_cls.task_type = subtask_class\nnew_cls.__doc__ = (\nf\"Correct segmentation of `{task_name}` tasks\"\nif description is None\nelse description\n)\nreturn new_cls\n</code></pre>"},{"location":"chat-completion/","title":"Using the Prompt Pipeline","text":"<p>To use the Prompt Pipeline in OpenAI Function Call, you need to instantiate a <code>ChatCompletion</code> object and build the API call by piping messages and functions to it.</p>"},{"location":"chat-completion/#the-chatcompletion-object","title":"The ChatCompletion Object","text":"<p>The <code>ChatCompletion</code> object is the starting point for constructing your API call. It provides the necessary methods and attributes to define the conversation flow and include function calls.</p>"},{"location":"chat-completion/#openai_function_call.dsl.completion.ChatCompletion","title":"<code>ChatCompletion</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>A chat completion is a collection of messages and configration options that can be used to generate a chat response from the OpenAI API.</p> Usage <p>In order to generate a chat response from the OpenAI API, you need to create a chat completion and then pipe it to a message and a <code>OpenAISchema</code>. Then when <code>create</code> or <code>acreate</code> is called we'll return the response from the API as an instance of <code>OpenAISchema</code>.</p> Example <pre><code>class Sum(OpenAISchema):\na: int\nb: int\ncompletion = (\nChatCompletion(\"example\")\n| TaggedMessage(content=\"What is 1 + 1?\", tag=\"question\")\n| Schema\n)\nprint(completion.create())\n# Sum(a=1, b=1)\n</code></pre> Tips <ul> <li>You can use the <code>|</code> operator to chain multiple messages and functions together</li> <li>There should be exactly one function call class (OpenAISchema) per chat completion</li> <li>System messages will be concatenated together</li> <li>Only one chain of thought message can be used per completion</li> </ul> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the chat completion</p> <code>model</code> <code>str</code> <p>The model to use for the chat completion (default: \"gpt-3.5-turbo-0613\")</p> <code>max_tokens</code> <code>int</code> <p>The maximum number of tokens to generate (default: 1000)</p> <code>temperature</code> <code>float</code> <p>The temperature to use for the chat completion (default: 0.1)</p> <code>stream</code> <code>bool</code> <p>Whether to stream the response from the API (default: False)</p> Warning <p>Currently we do not support streaming the response from the API, so the stream parameter is not supported yet.</p> Source code in <code>openai_function_call/dsl/completion.py</code> <pre><code>class ChatCompletion(BaseModel):\n\"\"\"\n    A chat completion is a collection of messages and configration options that can be used to\n    generate a chat response from the OpenAI API.\n    Usage:\n        In order to generate a chat response from the OpenAI API, you need to create a chat completion and then pipe it to a message and a `OpenAISchema`. Then when `create` or `acreate` is called we'll return the response from the API as an instance of `OpenAISchema`.\n    Example:\n        ```python\n        class Sum(OpenAISchema):\n            a: int\n            b: int\n        completion = (\n            ChatCompletion(\"example\")\n            | TaggedMessage(content=\"What is 1 + 1?\", tag=\"question\")\n            | Schema\n        )\n        print(completion.create())\n        # Sum(a=1, b=1)\n        ```\n    Tips:\n        * You can use the `|` operator to chain multiple messages and functions together\n        * There should be exactly one function call class (OpenAISchema) per chat completion\n        * System messages will be concatenated together\n        * Only one chain of thought message can be used per completion\n    Attributes:\n        name (str): The name of the chat completion\n        model (str): The model to use for the chat completion (default: \"gpt-3.5-turbo-0613\")\n        max_tokens (int): The maximum number of tokens to generate (default: 1000)\n        temperature (float): The temperature to use for the chat completion (default: 0.1)\n        stream (bool): Whether to stream the response from the API (default: False)\n    Warning:\n        Currently we do not support streaming the response from the API, so the stream parameter is not supported yet.\n    \"\"\"\nname: str\nmodel: str = Field(default=\"gpt-3.5-turbo-0613\")\nmax_tokens: int = Field(default=1000)\ntemperature: float = Field(default=0.1)\nstream: bool = Field(default=False)\nmessages: List[Message] = Field(default_factory=list, repr=False)\nsystem_message: Message = Field(default=None, repr=False)\ncot_message: ChainOfThought = Field(default=None, repr=False)\nfunction: OpenAISchema = Field(default=None, repr=False)\ndef __post_init__(self):\nassert self.stream == False, \"Stream is not supported yet\"\ndef __or__(self, other: Union[Message, OpenAISchema]) -&gt; \"ChatCompletion\":\n\"\"\"\n        Add a message or function to the chat completion, this can be used to chain multiple messages and functions together. It should contain some set of user or system messages along with a function call class (OpenAISchema)\n        \"\"\"\nif isinstance(other, Message):\nif other.role == MessageRole.SYSTEM:\nif not self.system_message:\nself.system_message = other  # type: ignore\nelse:\nself.system_message.content += \"\\n\\n\" + other.content\nelse:\nif isinstance(other, ChainOfThought):\nif self.cot_message:\nraise ValueError(\n\"Only one chain of thought message can be used per completion\"\n)\nself.cot_message = other\nself.messages.append(other)\nelse:\nif self.function:\nraise ValueError(\n\"Only one function can be used per completion, wrap your tools into a single toolkit schema\"\n)\nself.function = other\nassert self.model not in {\n\"gpt-3.5-turbo\",\n\"gpt-4\",\n}, \"Only *-0613 models can currently use functions\"\nreturn self\n@property\ndef kwargs(self) -&gt; dict:\n\"\"\"\n        Construct the kwargs for the OpenAI API call\n        Example:\n            ```python\n            result = openai.ChatCompletion.create(**self.kwargs)\n            ```\n        \"\"\"\nkwargs = {}\nmessages = []\nif self.system_message:\nmessages.append(self.system_message.dict())\nif self.messages:\nspecial_types = {\nSystemMessage,\nChainOfThought,\n}\nmessages += [\nmessage.dict()\nfor message in self.messages\nif type(message) not in special_types\n]\nif self.cot_message:\nmessages.append(self.cot_message.dict())\nkwargs[\"messages\"] = messages\nif self.function:\nkwargs[\"functions\"] = [self.function.openai_schema]\nkwargs[\"function_call\"] = {\"name\": self.function.openai_schema[\"name\"]}\nkwargs[\"max_tokens\"] = self.max_tokens\nkwargs[\"temperature\"] = self.temperature\nkwargs[\"model\"] = self.model\nreturn kwargs\ndef create(self):\n\"\"\"\n        Create a chat response from the OpenAI API\n        Returns:\n            response (OpenAISchema): The response from the OpenAI API\n        \"\"\"\nkwargs = self.kwargs\ncompletion = openai.ChatCompletion.create(**kwargs)\nif self.function:\nreturn self.function.from_response(completion)\nreturn completion\nasync def acreate(self):\n\"\"\"\n        Create a chat response from the OpenAI API asynchronously\n        Returns:\n            response (OpenAISchema): The response from the OpenAI API\n        \"\"\"\nkwargs = self.kwargs\ncompletion = openai.ChatCompletion.acreate(**kwargs)\nif self.function:\nreturn self.function.from_response(await completion)\nreturn await completion\n</code></pre>"},{"location":"chat-completion/#openai_function_call.dsl.completion.ChatCompletion.kwargs","title":"<code>kwargs: dict</code>  <code>property</code>","text":"<p>Construct the kwargs for the OpenAI API call</p> Example <pre><code>result = openai.ChatCompletion.create(**self.kwargs)\n</code></pre>"},{"location":"chat-completion/#openai_function_call.dsl.completion.ChatCompletion.__or__","title":"<code>__or__(other)</code>","text":"<p>Add a message or function to the chat completion, this can be used to chain multiple messages and functions together. It should contain some set of user or system messages along with a function call class (OpenAISchema)</p> Source code in <code>openai_function_call/dsl/completion.py</code> <pre><code>def __or__(self, other: Union[Message, OpenAISchema]) -&gt; \"ChatCompletion\":\n\"\"\"\n    Add a message or function to the chat completion, this can be used to chain multiple messages and functions together. It should contain some set of user or system messages along with a function call class (OpenAISchema)\n    \"\"\"\nif isinstance(other, Message):\nif other.role == MessageRole.SYSTEM:\nif not self.system_message:\nself.system_message = other  # type: ignore\nelse:\nself.system_message.content += \"\\n\\n\" + other.content\nelse:\nif isinstance(other, ChainOfThought):\nif self.cot_message:\nraise ValueError(\n\"Only one chain of thought message can be used per completion\"\n)\nself.cot_message = other\nself.messages.append(other)\nelse:\nif self.function:\nraise ValueError(\n\"Only one function can be used per completion, wrap your tools into a single toolkit schema\"\n)\nself.function = other\nassert self.model not in {\n\"gpt-3.5-turbo\",\n\"gpt-4\",\n}, \"Only *-0613 models can currently use functions\"\nreturn self\n</code></pre>"},{"location":"chat-completion/#openai_function_call.dsl.completion.ChatCompletion.acreate","title":"<code>acreate()</code>  <code>async</code>","text":"<p>Create a chat response from the OpenAI API asynchronously</p> <p>Returns:</p> Name Type Description <code>response</code> <code>OpenAISchema</code> <p>The response from the OpenAI API</p> Source code in <code>openai_function_call/dsl/completion.py</code> <pre><code>async def acreate(self):\n\"\"\"\n    Create a chat response from the OpenAI API asynchronously\n    Returns:\n        response (OpenAISchema): The response from the OpenAI API\n    \"\"\"\nkwargs = self.kwargs\ncompletion = openai.ChatCompletion.acreate(**kwargs)\nif self.function:\nreturn self.function.from_response(await completion)\nreturn await completion\n</code></pre>"},{"location":"chat-completion/#openai_function_call.dsl.completion.ChatCompletion.create","title":"<code>create()</code>","text":"<p>Create a chat response from the OpenAI API</p> <p>Returns:</p> Name Type Description <code>response</code> <code>OpenAISchema</code> <p>The response from the OpenAI API</p> Source code in <code>openai_function_call/dsl/completion.py</code> <pre><code>def create(self):\n\"\"\"\n    Create a chat response from the OpenAI API\n    Returns:\n        response (OpenAISchema): The response from the OpenAI API\n    \"\"\"\nkwargs = self.kwargs\ncompletion = openai.ChatCompletion.create(**kwargs)\nif self.function:\nreturn self.function.from_response(completion)\nreturn completion\n</code></pre>"},{"location":"chat-completion/#messages-types","title":"Messages Types","text":"<p>The basis of a message is defined as a <code>dataclass</code>. However, we provide helper functions and classes that provide additional functionality in the form of templates. </p>"},{"location":"chat-completion/#openai_function_call.dsl.messages.base.Message","title":"<code>Message</code>","text":"<p>A message class that helps build messages for the chat interface.</p> <p>Attributes:</p> Name Type Description <code>content</code> <code>str</code> <p>The content of the message.</p> <code>role</code> <code>MessageRole</code> <p>The role of the message.</p> <code>name</code> <code>Optional[str]</code> <p>The name of the user, only used if the role is USER.</p> Tips <p>If you want to make custom messages simple make a function that returns the <code>Message</code> class and use that as part of your pipes. For example if you want to add additional context:</p> <pre><code>def GetUserData(user_id) -&gt; Message:\ndata = ...\nreturn Message(\ncontent=\"This is some more user data: {data} for {user_id}\nrole=MessageRole.USER\n)\n</code></pre> Source code in <code>openai_function_call/dsl/messages/base.py</code> <pre><code>@dataclass\nclass Message:\n\"\"\"\n    A message class that helps build messages for the chat interface.\n    Attributes:\n        content (str): The content of the message.\n        role (MessageRole): The role of the message.\n        name (Optional[str]): The name of the user, only used if the role is USER.\n    Tips:\n        If you want to make custom messages simple make a function that returns the `Message` class and use that as part of your pipes. For example if you want to add additional context:\n        ```python\n        def GetUserData(user_id) -&gt; Message:\n            data = ...\n            return Message(\n                content=\"This is some more user data: {data} for {user_id}\n                role=MessageRole.USER\n            )\n        ```\n    \"\"\"\ncontent: str = Field(default=None, repr=True)\nrole: MessageRole = Field(default=MessageRole.USER, repr=False)\nname: Optional[str] = Field(default=None)\ndef dict(self):\nassert self.content is not None, \"Content must be set!\"\nobj = {\n\"role\": self.role.name.lower(),\n\"content\": self.content,\n}\nif self.name and self.role == MessageRole.USER:\nobj[\"name\"] = self.name\nreturn obj\n</code></pre>"},{"location":"chat-completion/#openai_function_call.dsl.messages.base.MessageRole","title":"<code>MessageRole</code>","text":"<p>             Bases: <code>Enum</code></p> <p>An enum that represents the role of a message.</p> <p>Attributes:</p> Name Type Description <code>USER</code> <p>A message from the user.</p> <code>SYSTEM</code> <p>A message from the system.</p> <code>ASSISTANT</code> <p>A message from the assistant.</p> Source code in <code>openai_function_call/dsl/messages/base.py</code> <pre><code>class MessageRole(Enum):\n\"\"\"\n    An enum that represents the role of a message.\n    Attributes:\n        USER: A message from the user.\n        SYSTEM: A message from the system.\n        ASSISTANT: A message from the assistant.\n    \"\"\"\nUSER = auto()\nSYSTEM = auto()\nASSISTANT = auto()\n</code></pre>"},{"location":"chat-completion/#helper-messages-templates","title":"Helper Messages / Templates","text":""},{"location":"chat-completion/#openai_function_call.dsl.messages.messages.ChainOfThought","title":"<code>ChainOfThought</code>","text":"<p>             Bases: <code>Message</code></p> <p>Special message type to correctly leverage chain of thought reasoning for the task. This is automatically set as the last message.</p> Source code in <code>openai_function_call/dsl/messages/messages.py</code> <pre><code>@dataclass\nclass ChainOfThought(Message):\n\"\"\"\n    Special message type to correctly leverage chain of thought reasoning\n    for the task. This is automatically set as the last message.\n    \"\"\"\ndef __post_init__(self):\nself.content = \"Lets think step by step to get the correct answer:\"\nself.role = MessageRole.ASSISTANT\n</code></pre>"},{"location":"chat-completion/#openai_function_call.dsl.messages.messages.SystemGuidelines","title":"<code>SystemGuidelines(guidelines)</code>","text":"<p>Create a system message that tells the user what guidelines they must follow when responding.</p> <p>Parameters:</p> Name Type Description Default <code>guidelines</code> <code>List[str]</code> <p>The guidelines the user must follow when responding.</p> required <p>Returns:</p> Name Type Description <code>message</code> <code>Message</code> <p>A system message that tells the user what guidelines they must follow when responding.</p> Source code in <code>openai_function_call/dsl/messages/messages.py</code> <pre><code>def SystemGuidelines(guidelines: List[str]) -&gt; Message:\n\"\"\"\n    Create a system message that tells the user what guidelines they must follow when responding.\n    Parameters:\n        guidelines (List[str]): The guidelines the user must follow when responding.\n    Returns:\n        message (Message): A system message that tells the user what guidelines they must follow when responding.\n    \"\"\"\nguideline_str = \"\\n* \".join(guidelines)\nreturn Message(\ncontent=f\"Here are the guidelines you must to follow when responding:\\n\\n* {guideline_str}\",\nrole=MessageRole.SYSTEM,\n)\n</code></pre>"},{"location":"chat-completion/#openai_function_call.dsl.messages.messages.SystemIdentity","title":"<code>SystemIdentity(identity)</code>","text":"<p>Create a system message that tells the user what their identity is.</p> <p>Parameters:</p> Name Type Description Default <code>identity</code> <code>str</code> <p>The identity of the user.</p> required <p>Returns:</p> Name Type Description <code>message</code> <code>Message</code> <p>A system message that tells the user what their identity is.</p> Source code in <code>openai_function_call/dsl/messages/messages.py</code> <pre><code>def SystemIdentity(identity: str) -&gt; Message:\n\"\"\"\n    Create a system message that tells the user what their identity is.\n    Parameters:\n        identity (str): The identity of the user.\n    Returns:\n        message (Message): A system message that tells the user what their identity is.\n    \"\"\"\nreturn Message(content=f\"You are a {identity.lower()}.\", role=MessageRole.SYSTEM)\n</code></pre>"},{"location":"chat-completion/#openai_function_call.dsl.messages.messages.SystemMessage","title":"<code>SystemMessage(content)</code>","text":"<p>Create a system message.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The content of the message.</p> required <p>Returns:</p> Name Type Description <code>message</code> <code>Message</code> <p>A system message.</p> Source code in <code>openai_function_call/dsl/messages/messages.py</code> <pre><code>def SystemMessage(content: str) -&gt; Message:\n\"\"\"\n    Create a system message.\n    Parameters:\n        content (str): The content of the message.\n    Returns:\n        message (Message): A system message.\"\"\"\nreturn Message(content=content, role=MessageRole.SYSTEM)\n</code></pre>"},{"location":"chat-completion/#openai_function_call.dsl.messages.messages.SystemStyle","title":"<code>SystemStyle(style)</code>","text":"<p>Create a system message that tells the user what style they are responding in.</p> <p>Parameters:</p> Name Type Description Default <code>style</code> <code>str</code> <p>The style the user is responding in.</p> required <p>Returns:</p> Name Type Description <code>message</code> <code>Message</code> <p>A system message that tells the user what style they are responding in.</p> Source code in <code>openai_function_call/dsl/messages/messages.py</code> <pre><code>def SystemStyle(style: str) -&gt; Message:\n\"\"\"\n    Create a system message that tells the user what style they are responding in.\n    Parameters:\n        style (str): The style the user is responding in.\n    Returns:\n        message (Message): A system message that tells the user what style they are responding in.\n    \"\"\"\nreturn Message(\ncontent=f\"You must respond with in following style: {style.lower()}.\",\nrole=MessageRole.SYSTEM,\n)\n</code></pre>"},{"location":"chat-completion/#openai_function_call.dsl.messages.messages.SystemTask","title":"<code>SystemTask(task)</code>","text":"<p>Create a system message that tells the user what task they are doing, uses language to push the system to behave as a world class algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>str</code> <p>The task the user is doing.</p> required <p>Returns:</p> Name Type Description <code>message</code> <code>Message</code> <p>A system message that tells the user what task they are doing.</p> Source code in <code>openai_function_call/dsl/messages/messages.py</code> <pre><code>def SystemTask(task: str) -&gt; Message:\n\"\"\"\n    Create a system message that tells the user what task they are doing, uses language to\n    push the system to behave as a world class algorithm.\n    Parameters:\n        task (str): The task the user is doing.\n    Returns:\n        message (Message): A system message that tells the user what task they are doing.\n    \"\"\"\nreturn Message(\ncontent=f\"You are a world class state of the art algorithm capable of correctly completing the following task: `{task}`.\",\nrole=MessageRole.SYSTEM,\n)\n</code></pre>"},{"location":"chat-completion/#openai_function_call.dsl.messages.messages.SystemTips","title":"<code>SystemTips(tips)</code>","text":"<p>Create a system message that gives the user some tips before responding.</p> <p>Parameters:</p> Name Type Description Default <code>tips</code> <code>List[str]</code> <p>The tips the user should follow when responding.</p> required <p>Returns:</p> Name Type Description <code>message</code> <code>Message</code> <p>A system message that gives the user some tips before responding.</p> Source code in <code>openai_function_call/dsl/messages/messages.py</code> <pre><code>def SystemTips(tips: List[str]) -&gt; Message:\n\"\"\"\n    Create a system message that gives the user some tips before responding.\n    Parameters:\n        tips (List[str]): The tips the user should follow when responding.\n    Returns:\n        message (Message): A system message that gives the user some tips before responding.\n    \"\"\"\ntips_str = \"\\n* \".join(tips)\nreturn Message(\ncontent=f\"Here are some tips before responding:\\n\\n* {tips_str}\",\nrole=MessageRole.SYSTEM,\n)\n</code></pre>"},{"location":"chat-completion/#openai_function_call.dsl.messages.user.TaggedMessage","title":"<code>TaggedMessage(content, tag='data', header='Consider the following data:')</code>","text":"<p>Create a user message.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The content of the message.</p> required <code>tag</code> <code>str</code> <p>The tag to use, will show up as content.</p> <code>'data'</code> <code>header</code> <code>str</code> <p>The header to reference the data</p> <code>'Consider the following data:'</code> <p>Returns:</p> Name Type Description <code>message</code> <code>Message</code> <p>A user message with the data tagged.</p> Source code in <code>openai_function_call/dsl/messages/user.py</code> <pre><code>def TaggedMessage(\ncontent: str, tag: str = \"data\", header: str = \"Consider the following data:\"\n) -&gt; Message:\n\"\"\"\n    Create a user message.\n    Parameters:\n        content (str): The content of the message.\n        tag (str): The tag to use, will show up as &lt;tag&gt;content&lt;/tag&gt;.\n        header (str): The header to reference the data\n    Returns:\n        message (Message): A user message with the data tagged.\n    \"\"\"\ncontent = f\"{header}\\n\\n&lt;{tag}&gt;{content}&lt;/{tag}&gt;\"\nreturn Message(content=content, role=MessageRole.USER)\n</code></pre>"},{"location":"chat-completion/#openai_function_call.dsl.messages.user.TipsMessage","title":"<code>TipsMessage(tips, header='Here are some tips to help you complete the task')</code>","text":"<p>Create a system message that gives the user tips to help them complete the task.</p> <p>Parameters:</p> Name Type Description Default <code>tips</code> <code>List[str]</code> <p>A list of tips to help the user complete the task.</p> required <code>header</code> <code>str</code> <p>The header of the message.</p> <code>'Here are some tips to help you complete the task'</code> <p>Returns:</p> Name Type Description <code>message</code> <code>Message</code> <p>A user message that gives the user tips to help them complete the</p> Source code in <code>openai_function_call/dsl/messages/user.py</code> <pre><code>def TipsMessage(\ntips: List[str], header: str = \"Here are some tips to help you complete the task\"\n) -&gt; Message:\n\"\"\"\n    Create a system message that gives the user tips to help them complete the task.\n    Parameters:\n        tips (List[str]): A list of tips to help the user complete the task.\n        header (str): The header of the message.\n    Returns:\n        message (Message): A user message that gives the user tips to help them complete the\n    \"\"\"\ntips_str = \"\\n* \".join(tips)\nreturn Message(\ncontent=f\"{header}:\\n\\n* {tips_str}\",\nrole=MessageRole.USER,\n)\n</code></pre>"},{"location":"chat-completion/#openai_function_call.dsl.messages.user.UserMessage","title":"<code>UserMessage(content)</code>","text":"<p>Create a user message.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The content of the message.</p> required <p>Returns:</p> Name Type Description <code>message</code> <code>Message</code> <p>A user message.</p> Source code in <code>openai_function_call/dsl/messages/user.py</code> <pre><code>def UserMessage(content: str) -&gt; Message:\n\"\"\"\n    Create a user message.\n    Parameters:\n        content (str): The content of the message.\n    Returns:\n        message (Message): A user message.\n    \"\"\"\nreturn Message(content=content, role=MessageRole.USER)\n</code></pre>"},{"location":"multitask/","title":"Patterns for Multiple Extraction","text":"<p>A common use case of structured extraction is defining a single schema class and then making another schema to create a list to do multiple extraction</p> <pre><code>class User(OpenAISchema):\nname: str\nage: int\nclass Users(OpenAISchema):\nusers: List[User]\n</code></pre> <p>Defining a task and creating a list of classes is a common enough pattern that we define a helper function <code>MultiTask</code> It procides a function to dynamically create a new class that:</p> <ol> <li>Dynamic docstrings and class name baed on the task</li> <li>Helper method to support streaming by collectin function_call tokens until a object back out.</li> </ol>"},{"location":"multitask/#extracting-tasks","title":"Extracting Tasks","text":"<p>By using multitask you get a very convient class with prompts and names automatically defined. You get <code>from_response</code> just like any other <code>OpenAISchema</code> you're able to extract the list of objects data you want with <code>MultTask.tasks</code>.</p> <pre><code>from openai_function_call import OpenAISchema, MultiTask\nclass User(OpenAISchema):\nname: str\nage: int\nMultiUser = MultiTask(User)\ncompletion = openai.ChatCompletion.create(\nmodel=\"gpt-4-0613\",\ntemperature=0.1,\nstream=False,\nfunctions=[MultiUser.openai_schema],\nfunction_call={\"name\": MultiUser.openai_schema[\"name\"]},\nmessages=[\n{\n\"role\": \"user\",\n\"content\": f\"Consider the data below: Jason is 10 and John is 30\",\n},\n],\nmax_tokens=1000,\n)\nMultiUser.from_response(completion)\n</code></pre> <pre><code>{\"tasks\": [\n{\"name\": \"Jason\", \"age\": 10},\n    {\"name\": \"John\", \"age\": 30}\n]}\n</code></pre>"},{"location":"multitask/#streaming-tasks","title":"Streaming Tasks","text":"<p>Since a <code>MultiTask(T)</code> is well contrained to <code>tasks: List[T]</code> we can make assuptions on how tokens are used and provide a helper method that allows you generate tasks as the the tokens are streamed in</p> <p>Why would we want this?</p> <p>While <code>gpt-3.5-turbo</code> is quite fast <code>gpt-4</code> will take a while if there are many objects or if each object schema is complex. If 10 entities are created and takes 100ms to complete it would mean that it would take 1 second before we had access to our objects. With streaming you'd get the first object in 100ms a 10x percieved improvement in latency! While this may not make sense for more usecases if we were dynamitcally building UI based on entities, streaming entities 1 by 1 could improve the user experience dramatically.</p> <p>Lets look at an example in action with the same class</p> <pre><code>MultiUser = MultiTask(User)\ncompletion = openai.ChatCompletion.create(\nmodel=\"gpt-4-0613\",\ntemperature=0.1,\nstream=True,\nfunctions=[MultiUser.openai_schema],\nfunction_call={\"name\": MultiUser.openai_schema[\"name\"]},\nmessages=[\n{\n\"role\": \"system\",\n\"content\": \"You are a perfect entity extraction system\",\n},\n{\n\"role\": \"user\",\n\"content\": (\nf\"Consider the data below:\\n{input}\"\n\"Correctly segment it into entitites\"\n\"Make sure the JSON is correct\"\n),\n},\n],\nmax_tokens=1000,\n)\nfor user in MultiUser.from_streaming_response(completion):\nassert isinstance(user, User)\nprint(user)\n&gt;&gt;&gt; name=\"Jason\" \"age\"=10\n&gt;&gt;&gt; name=\"John\" \"age\"=10\n</code></pre> <p>How??</p> <p>Consider this incomplete json string.</p> <pre><code>{\"tasks\": [{\"name\": \"Jason\", \"age\": 10}\n</code></pre> <p>Notice how, while this isn't valid json, we know that one complete <code>User</code> object was generated so we <code>yield</code> that object to be used elsewhere as soon as possible.</p> <p>This streaming is still a prototype, but should work quite well for simple schemas.</p>"},{"location":"openai_schema/","title":"OpenAI Schema","text":"<p>The <code>OpenAISchema</code> is an extension of <code>Pydantic.BaseModel</code> that offers a minimally invasive way to define schemas for OpenAI completions. It provides two main methods: <code>openai_schema</code> to generate the correct schema and <code>from_response</code> to create an instance of the class from the completion result.</p>"},{"location":"openai_schema/#prompt-placement","title":"Prompt Placement","text":"<p>Our philosophy is to keep prompts close to the code. This is achieved by using docstrings and field descriptions to provide prompts and descriptions for your schema fields.</p>"},{"location":"openai_schema/#structured-extraction","title":"Structured Extraction","text":"<p>You can directly use the <code>OpenAISchema</code> class in your <code>openai</code> API create calls by passing in the <code>openai_schema</code> class property and extracting the class out using the <code>from_response</code> method. This style of usage provides full control over configuration and prompting.</p> <pre><code>import openai\nfrom openai_function_call import OpenAISchema\nfrom pydantic import Field\nclass UserDetails(OpenAISchema):\n\"\"\"Details of a user\"\"\"\nname: str = Field(..., description=\"User's full name\")\nage: int\ncompletion = openai.ChatCompletion.create(\nmodel=\"gpt-3.5-turbo-0613\",\nfunctions=[UserDetails.openai_schema],\nfunction_call={\"name\": UserDetails.openai_schema[\"name\"]},\nmessages=[\n{\"role\": \"system\", \"content\": \"Extract user details from my requests\"},\n{\"role\": \"user\", \"content\": \"My name is John Doe and I'm 30 years old.\"},\n],\n)\nuser_details = UserDetails.from_response(completion)\nprint(user_details)  # UserDetails(name='John Doe', age=30)\n</code></pre> <p>You can also use the <code>@openai_schema</code> decorator to decorate <code>BaseModels</code>, but you may lose some type hinting as a result.</p> <pre><code>import openai\nfrom openai_function_call import openai_schema\nfrom pydantic import Field, BaseModel\n@openai_schema\nclass UserDetails(BaseModel):\n\"\"\"Details of a user\"\"\"\nname: str = Field(..., description=\"User's full name\")\nage: int\n</code></pre>"},{"location":"openai_schema/#code-reference","title":"Code Reference","text":"<p>For more information about the code, including the complete API reference, please refer to the <code>openai_function_call</code> documentation.</p>"},{"location":"openai_schema/#openai_function_call.function_calls.OpenAISchema","title":"<code>OpenAISchema</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>openai_function_call/function_calls.py</code> <pre><code>class OpenAISchema(BaseModel):\n@classmethod\n@property\ndef openai_schema(cls):\n\"\"\"\n        Return the schema in the format of OpenAI's schema as jsonschema\n        Note:\n            Its important to add a docstring to describe how to best use this class, it will be included in the description attribute and be part of the prompt.\n        Returns:\n            model_json_schema (dict): A dictionary in the format of OpenAI's schema as jsonschema\n        \"\"\"\nschema = cls.model_json_schema()\nparameters = {\nk: v for k, v in schema.items() if k not in (\"title\", \"description\")\n}\nparameters[\"required\"] = sorted(parameters[\"properties\"])\nif \"description\" not in schema:\nschema[\n\"description\"\n] = f\"Correctly extracted `{cls.__name__}` with all the required parameters with correct types\"\nreturn {\n\"name\": schema[\"title\"],\n\"description\": schema[\"description\"],\n\"parameters\": parameters,\n}\n@classmethod\ndef from_response(cls, completion, throw_error=True):\n\"\"\"Execute the function from the response of an openai chat completion\n        Parameters:\n            completion (openai.ChatCompletion): The response from an openai chat completion\n            throw_error (bool): Whether to throw an error if the function call is not detected\n        Returns:\n            cls (OpenAISchema): An instance of the class\n        \"\"\"\nmessage = completion.choices[0].message\nif throw_error:\nassert \"function_call\" in message, \"No function call detected\"\nassert (\nmessage[\"function_call\"][\"name\"] == cls.openai_schema[\"name\"]\n), \"Function name does not match\"\nfunction_call = message[\"function_call\"]\narguments = json.loads(function_call[\"arguments\"])\nreturn cls(**arguments)\n</code></pre>"},{"location":"openai_schema/#openai_function_call.function_calls.OpenAISchema.openai_schema","title":"<code>openai_schema</code>  <code>classmethod</code> <code>property</code>","text":"<p>Return the schema in the format of OpenAI's schema as jsonschema</p> Note <p>Its important to add a docstring to describe how to best use this class, it will be included in the description attribute and be part of the prompt.</p> <p>Returns:</p> Name Type Description <code>model_json_schema</code> <code>dict</code> <p>A dictionary in the format of OpenAI's schema as jsonschema</p>"},{"location":"openai_schema/#openai_function_call.function_calls.OpenAISchema.from_response","title":"<code>from_response(completion, throw_error=True)</code>  <code>classmethod</code>","text":"<p>Execute the function from the response of an openai chat completion</p> <p>Parameters:</p> Name Type Description Default <code>completion</code> <code>openai.ChatCompletion</code> <p>The response from an openai chat completion</p> required <code>throw_error</code> <code>bool</code> <p>Whether to throw an error if the function call is not detected</p> <code>True</code> <p>Returns:</p> Name Type Description <code>cls</code> <code>OpenAISchema</code> <p>An instance of the class</p> Source code in <code>openai_function_call/function_calls.py</code> <pre><code>@classmethod\ndef from_response(cls, completion, throw_error=True):\n\"\"\"Execute the function from the response of an openai chat completion\n    Parameters:\n        completion (openai.ChatCompletion): The response from an openai chat completion\n        throw_error (bool): Whether to throw an error if the function call is not detected\n    Returns:\n        cls (OpenAISchema): An instance of the class\n    \"\"\"\nmessage = completion.choices[0].message\nif throw_error:\nassert \"function_call\" in message, \"No function call detected\"\nassert (\nmessage[\"function_call\"][\"name\"] == cls.openai_schema[\"name\"]\n), \"Function name does not match\"\nfunction_call = message[\"function_call\"]\narguments = json.loads(function_call[\"arguments\"])\nreturn cls(**arguments)\n</code></pre>"},{"location":"openai_schema/#openai_function_call.function_calls.openai_function","title":"<code>openai_function</code>","text":"<p>Decorator to convert a function into an OpenAI function.</p> <p>This decorator will convert a function into an OpenAI function. The function will be validated using pydantic and the schema will be generated from the function signature.</p> Example <pre><code>@openai_function\ndef sum(a: int, b: int) -&gt; int:\nreturn a + b\ncompletion = openai.ChatCompletion.create(\n...\nmessages=[{\n\"content\": \"What is 1 + 1?\",\n\"role\": \"user\"\n}]\n)\nsum.from_response(completion)\n# 2\n</code></pre> Source code in <code>openai_function_call/function_calls.py</code> <pre><code>class openai_function:\n\"\"\"\n    Decorator to convert a function into an OpenAI function.\n    This decorator will convert a function into an OpenAI function. The\n    function will be validated using pydantic and the schema will be\n    generated from the function signature.\n    Example:\n        ```python\n        @openai_function\n        def sum(a: int, b: int) -&gt; int:\n            return a + b\n        completion = openai.ChatCompletion.create(\n            ...\n            messages=[{\n                \"content\": \"What is 1 + 1?\",\n                \"role\": \"user\"\n            }]\n        )\n        sum.from_response(completion)\n        # 2\n        ```\n    \"\"\"\ndef __init__(self, func: Callable) -&gt; None:\nself.func = func\nself.validate_func = validate_arguments(func)\nparameters = self.validate_func.model.model_json_schema()\nparameters[\"properties\"] = {\nk: v\nfor k, v in parameters[\"properties\"].items()\nif k not in (\"v__duplicate_kwargs\", \"args\", \"kwargs\")\n}\nparameters[\"required\"] = sorted(\nparameters[\"properties\"]\n)  # bug workaround see lc\n_remove_a_key(parameters, \"additionalProperties\")\nself.openai_schema = {\n\"name\": self.func.__name__,\n\"description\": self.func.__doc__,\n\"parameters\": parameters,\n}\nself.model = self.validate_func.model\ndef __call__(self, *args: Any, **kwargs: Any) -&gt; Any:\n@wraps(self.func)\ndef wrapper(*args, **kwargs):\nreturn self.validate_func(*args, **kwargs)\nreturn wrapper(*args, **kwargs)\ndef from_response(self, completion, throw_error=True):\n\"\"\"\n        Parse the response from OpenAI's API and return the function call\n        Parameters:\n            completion (openai.ChatCompletion): The response from OpenAI's API\n            throw_error (bool): Whether to throw an error if the response does not contain a function call\n        Returns:\n            result (any): result of the function call\n        \"\"\"\nmessage = completion.choices[0].message\nif throw_error:\nassert \"function_call\" in message, \"No function call detected\"\nassert (\nmessage[\"function_call\"][\"name\"] == self.openai_schema[\"name\"]\n), \"Function name does not match\"\nfunction_call = message[\"function_call\"]\narguments = json.loads(function_call[\"arguments\"])\nreturn self.validate_func(**arguments)\n</code></pre>"},{"location":"openai_schema/#openai_function_call.function_calls.openai_function.from_response","title":"<code>from_response(completion, throw_error=True)</code>","text":"<p>Parse the response from OpenAI's API and return the function call</p> <p>Parameters:</p> Name Type Description Default <code>completion</code> <code>openai.ChatCompletion</code> <p>The response from OpenAI's API</p> required <code>throw_error</code> <code>bool</code> <p>Whether to throw an error if the response does not contain a function call</p> <code>True</code> <p>Returns:</p> Name Type Description <code>result</code> <code>any</code> <p>result of the function call</p> Source code in <code>openai_function_call/function_calls.py</code> <pre><code>def from_response(self, completion, throw_error=True):\n\"\"\"\n    Parse the response from OpenAI's API and return the function call\n    Parameters:\n        completion (openai.ChatCompletion): The response from OpenAI's API\n        throw_error (bool): Whether to throw an error if the response does not contain a function call\n    Returns:\n        result (any): result of the function call\n    \"\"\"\nmessage = completion.choices[0].message\nif throw_error:\nassert \"function_call\" in message, \"No function call detected\"\nassert (\nmessage[\"function_call\"][\"name\"] == self.openai_schema[\"name\"]\n), \"Function name does not match\"\nfunction_call = message[\"function_call\"]\narguments = json.loads(function_call[\"arguments\"])\nreturn self.validate_func(**arguments)\n</code></pre>"},{"location":"philosophy/","title":"Philosophy","text":"<p>The philosophy behind this library is to provide a lightweight and flexible approach to leveraging language models (LLMs) to do structured output without imposing unnecessary dependencies or abstractions.</p> <p>By treating LLMs as just another function that returns a typed object, this library aims to remove the perceived complexity and make working with LLMs more approachable. It provides a flexible foundation for incorporating LLMs into your projects while allowing you to leverage the full power of Python to write your own code.</p> <ol> <li>Define a Schema <code>class StructuredData(OpenAISchema):</code></li> <li>Encapsulate all your LLM logic into a function <code>def extract(a) -&gt; StructuredData:</code> </li> <li>Define typed computations against your data with <code>def compute(data: StructuredData):</code></li> </ol> <p>Here are some key points to understand:</p> <ul> <li> <p>Minimal Installation: This library is designed to be lightweight. If you prefer not to install the library and its two dependencies, you can simply extract the <code>function_calls.py</code> file from the code and incorporate it directly into your project. Own it. It is a single script. </p> </li> <li> <p>Code as prompts: With both the DSL and the structured extraction we don't make a distinction between a code vs a <code>prompt template</code>. We believe the prompts that go into a LLM should be constructed and collocated with the code we need to execute. Prompts are created via docstrings, descriptions and functions that construct messages.</p> </li> <li> <p>Writing Prompts: The library also includes an experimental prompt pipeline api. The DSL is a thin wrapper that aims to improve code readability by adding light abstraction around templates as messages. It provides a slightly more intuitive syntax for working with LLMs, making the prompting easier to read.</p> <ul> <li>No Abstractions for Retrieval or Execution: The library does not impose any abstractions for retrieval or execution. Python code is considered to be great glue code, and there is no need to force the use of additional abstractions. You have the freedom to use any retrieval or execution mechanism that suits your needs.</li> </ul> <p>Roll your own</p> <p>If you want to do retrival simply make a class that extracts a query and implement a method that calls to get the data!</p> <pre><code>import ...\nclass Search(OpenAISchema):\n\"Extract the search query from a question a query\"\nquery: str \ndef execute(self):\nreturn vectordb.query(self.query).to_string()\nreq = (\nChatCompletion(\"Query Extraction\")\n| TaggedMessage(content=\"can you tell me who is Jason Liu?\", tag=\"query\")\n| Search\n) \nquery = req.create() # Search(query=\"Jason Liu\")\nquery.execute()      # \"Jason Liu has a twitter account @jxnlco\"\n</code></pre> <ul> <li>Message as the Building Block: In the DSL, the fundamental building block is a message or an OpenAI schema call. Retrieval should be implemented as code that returns a message to be used in retrieval-augmented generation. This approach allows for flexibility and customization in handling different types of inputs and outputs.</li> </ul> <p>Roll your own, again</p> <p>If you want to do augmentation, you can simple make a function that returns the data in a message and <code>|</code> it back into the completion.</p> <pre><code>import ...\nclass Response(OpenAISchema):\n\"Question answer pairs\"\nquestion: str\nanswer: str\ndef augment(query):\nreturn TaggedMessage(content=vectordb.query(self.query).to_string(), tag=\"data\")\nquery = \"does jason have social media?\"\nreq = (\nChatCompletion(\"Q/A System\")\n| augment(query=query)\n| UserMessage(f\"Use the data to answer the question: {query}\")\n| Response\n)\nresponse = req.create()\n# Response(\n#   question=\"does jason have social media?\", \n#   answer=\"yes, his twitter is @jxnlco\n# )\n</code></pre> </li> </ul> <p>Please note that the library is designed to be adaptable and open-ended, allowing you to customize and extend its functionality based on your specific requirements.</p> <p>If you have any further questions or ideas hit me up on twitter</p>"},{"location":"writing-prompts/","title":"Writing prompts with <code>ChatCompletion</code>","text":"<p>The ChatCompletion pipeline API provides a convenient way to build prompts with clear instructions and structure. It helps avoid the need to remember best practices for wording and prompt construction. This documentation will demonstrate an example pipeline and guide you through the process of using it.</p> <p>Our goals are to:</p> <ol> <li>Define some best practices with a light abstraction over a chat message</li> <li>Allow the pipeline to be intuitive and readable.</li> <li>Abstract the output shape and deserialization to better usability</li> </ol>"},{"location":"writing-prompts/#example-pipeline","title":"Example Pipeline","text":"<p>We will begin by defining a task to segment queries and add instructions using the prompt pipeline API.</p> <ol> <li>We want to define a search object to extract</li> <li>We want to extract multiple instances of such an object</li> <li>We want to define the pipeline with a set of instructions</li> <li>We want to easily call OpenAI and extract the data back out of the competion</li> </ol> <p>Applications</p> <p>Extracted a repeated task out of instructions is a fairly common task. Prompting tips have been to define the task clearly, model the output object and provide tips to the llm for better performance. Something like this can be used to power agents like Siri or Alexa in performing multiple tasks in one request. Read more</p>"},{"location":"writing-prompts/#designing-the-schema","title":"Designing the Schema","text":"<p>First, let's design the schema for our task. In this example, we will have a <code>SearchQuery</code> schema with a single field called <code>query</code>. The <code>query</code> field will represent a detailed, comprehensive, and specific query to be used for semantic search.</p> <pre><code>from openai_function_call import OpenAISchema, dsl\nfrom pydantic import Field\nclass SearchQuery(OpenAISchema):\nquery: str = Field(\n...,\ndescription=\"Detailed, comprehensive, and specific query to be used for semantic search\",\n)\nSearchResponse = dsl.MultiTask(\nsubtask_class=SearchQuery,\n)\n</code></pre> <p>MultiTask</p> <p>To learn more about the <code>MultiTask</code> functionality, you can refer to the MultiTask documentation.</p>"},{"location":"writing-prompts/#building-our-prompts","title":"Building our Prompts","text":"<p>Next, let's write out prompt using the pipeline style. We will leverage the features provided by the <code>ChatCompletion</code> class and utilize the <code>|</code> operator to chain different components of our prompt together.</p> <pre><code>task = (\ndsl.ChatCompletion(#(1)!\nname=\"Segmenting Search requests example\",\nmodel='gpt-3.5-turbo-0613,\nmax_token=1000) \n| dsl.SystemTask(task=\"Segment search results\") #(2)!\n| dsl.TaggedMessage(#(3)!\ncontent=\"can you send me the data about the video investment and the one about spot the dog?\",\ntag=\"query\") \n| dsl.TipsMessage(#(4)!\ntips=[\n\"Expand query to contain multiple forms of the same word (SSO -&gt; Single Sign On)\",\n\"Use the title to explain what the query should return, but use the query to complete the search\",\n\"The query should be detailed, specific, and cast a wide net when possible\",\n]) \n| SearchResponse #(5)!\n)\n</code></pre> <ol> <li>Define the completion object (consider this both task and prompt)</li> <li>SystemTask augments the <code>task</code> with \"You are a world class ... correctly complete the task: {task}\"</li> <li>TaggedMessage wraps content with <code>&lt;query&gt;&lt;/query&gt;</code> to set clear boundaries for the data you wish to process</li> <li>TipsMessages allows you to pass a list of strings as tips as a result we can potentially create this list dynamically</li> <li>Last step defines the output model you want to use to parse the results if no output model is defined we revert to the usual openai completion.</li> </ol> <p>The <code>ChatCompletion</code> class is responsible for model configuration, while the <code>|</code> operator allows us to construct the prompt in a readable manner. We can add <code>Messages</code> or <code>OpenAISchema</code> components to the prompt pipeline using <code>|</code>, and the <code>ChatCompletion</code> class will handle the prompt construction for us.</p> <p>In the above example, we:</p> <ul> <li>Initialize a <code>ChatCompletion</code> object with the desired model and maximum token count.</li> <li>Add a <code>SystemTask</code> component to segment search results.</li> <li>Include a <code>TaggedMessage</code> component to provide a query with a specific tag.</li> <li>Use a <code>TipsMessage</code> component to include some helpful tips related to the task.</li> <li>Connect the <code>SearchResponse</code> schema to the pipeline.</li> </ul> <p>Lastly, we create the <code>search_request</code> using <code>task.create()</code>. The <code>search_request</code> object will be of type <code>SearchResponse</code>, and we can print it as a JSON object.</p> <p>Tip</p> <p>If you want to see the exact input sent to OpenAI, scroll to the bottom of the page.</p> <pre><code>search_request = task.create()  # type: ignore\nassert isinstance(search_request, SearchResponse)\nprint(search_request.json(indent=2))\n</code></pre> <p>The output will be a JSON object containing the segmented search queries.</p> <pre><code>{\n\"tasks\": [\n{\n\"query\": \"data about video investment\"\n},\n{\n\"query\": \"data about spot the dog\"\n}\n]\n}\n</code></pre>"},{"location":"writing-prompts/#inspecting-the-api-call","title":"Inspecting the API Call","text":"<p>To make it easy for you to understand what this api is doing we default only construct the kwargs for the chat completion call.</p> <pre><code>print(task.kwargs)\n</code></pre> <pre><code>{\n\"messages\": [\n{\n\"role\": \"system\",\n\"content\": \"You are a world class state of the art algorithm capable of correctly completing the following task: `Segment search results`.\"\n},\n{\n\"role\": \"user\",\n\"content\": \"Consider the following data:\\n\\n&lt;query&gt;can you send me the data about the video investment and the one about spot the dog?&lt;/query&gt;\"\n},\n{\n\"role\": \"user\",\n\"content\": \"Here are some tips to help you complete the task:\\n\\n* Expand query to contain multiple forms of the same word (SSO -&gt; Single Sign On)\\n* Use the title to explain what the query should return, but use the query to complete the search\\n* The query should be detailed, specific, and cast a wide net when possible\"\n}\n],\n\"functions\": [\n{\n\"name\": \"MultiSearchQuery\",\n\"description\": \"Correctly segmented set of search queries\",\n\"parameters\": {\n\"type\": \"object\",\n\"properties\": {\n\"tasks\": {\n\"description\": \"Correctly segmented list of `SearchQuery` tasks\",\n\"type\": \"array\",\n\"items\": {\n\"$ref\": \"#/definitions/SearchQuery\"\n}\n}\n},\n\"definitions\": {\n\"SearchQuery\": {\n\"type\": \"object\",\n\"properties\": {\n\"query\": {\n\"description\": \"Detailed, comprehensive, and specific query to be used for semantic search\",\n\"type\": \"string\"\n}\n},\n\"required\": [\n\"query\"\n]\n}\n},\n\"required\": [\n\"tasks\"\n]\n}\n}\n],\n\"function_call\": {\n\"name\": \"MultiSearchQuery\"\n},\n\"max_tokens\": 1000,\n\"temperature\": 0.1,\n\"model\": \"gpt-3.5-turbo-0613\"\n}\n</code></pre>"},{"location":"examples/","title":"Function Calls by Example","text":"<p>Welcome to the examples page. Here you will find emails that highlight a range of use cases, on how to use our code and examples demonstrating various features and functionalities.</p>"},{"location":"examples/#quick-links","title":"Quick Links","text":"<ul> <li>Segmenting search requests into multiple search queries</li> <li>One shot query planning</li> <li>Using recursive schema</li> <li>Exact citations using regex</li> <li>Automated database extraction from text</li> <li>Creating multiple file programs</li> </ul>"},{"location":"examples/#details","title":"Details","text":"<p>In this section, you will find examples demonstrating different aspects of our project's functionality.</p> <ul> <li> <p>Segmented Search: Learn how to perform segmented search using a multi task definition using function calling </p> </li> <li> <p>One shot Query Planning: Explore how to plan and decompose a complex query into multiple subqueries in a single request.</p> </li> <li> <p>Recursive Schemas: Understand how to work with recursive schemas, and also why flat is better than nested.</p> </li> <li> <p>Exact Citations: Find out how to generate exact citations by using smart prompting and regular expressions</p> </li> <li> <p>Automated Dataframe Extraction: Discover how to automate dataframe extraction to not only return a table, but possibly multiple tables.</p> </li> <li> <p>Creating Multiple File Programs: Master how to create multiple file programs based on specification using function calling.</p> </li> </ul> <p>Feel free to explore these examples to gain a better understanding of various patterns on how creative prompting, description, and structuring of <code>OpenAISchema</code> and unlock new capabilities.</p> <p>If you have any questions or need further assistance, please refer to the specific example documentation or reach out to our support team.</p> <p>Happy exploring!</p>"},{"location":"examples/autodataframe/","title":"Example: Converting Text into Dataframes","text":"<p>In this example, we'll demonstrate how to convert a text into dataframes using OpenAI Function Call. We will define the necessary data structures using Pydantic and show how to convert the text into dataframes.</p> <p>Motivation</p> <p>Often times when we parse data we have an opportunity to extract structured data, what if we could extract an arbitrary number of tables with arbitrary schemas? By pulling out dataframes we could write tables or .csv files and attach them to our retrieved data.</p>"},{"location":"examples/autodataframe/#defining-the-data-structures","title":"Defining the Data Structures","text":"<p>Let's start by defining the data structures required for this task: <code>RowData</code>, <code>Dataframe</code>, and <code>Database</code>.</p> <pre><code>from openai_function_call import OpenAISchema\nfrom pydantic import Field\nfrom typing import List, Any\nclass RowData(OpenAISchema):\nrow: List[Any] = Field(..., description=\"The values for each row\")\ncitation: str = Field(\n..., description=\"The citation for this row from the original source data\"\n)\nclass Dataframe(OpenAISchema):\n\"\"\"\n    Class representing a dataframe. This class is used to convert\n    data into a frame that can be used by pandas.\n    \"\"\"\nname: str = Field(..., description=\"The name of the dataframe\")\ndata: List[RowData] = Field(\n...,\ndescription=\"Correct rows of data aligned to column names, Nones are allowed\",\n)\ncolumns: List[str] = Field(\n...,\ndescription=\"Column names relevant from source data, should be in snake_case\",\n)\ndef to_pandas(self):\nimport pandas as pd\ncolumns = self.columns + [\"citation\"]\ndata = [row.row + [row.citation] for row in self.data]\nreturn pd.DataFrame(data=data, columns=columns)\nclass Database(OpenAISchema):\n\"\"\"\n    A set of correct named and defined tables as dataframes\n    \"\"\"\ntables: List[Dataframe] = Field(\n...,\ndescription=\"List of tables in the database\",\n)\n</code></pre> <p>The <code>RowData</code> class represents a single row of data in the dataframe. It contains a <code>row</code> attribute for the values in each row and a <code>citation</code> attribute for the citation from the original source data.</p> <p>The <code>Dataframe</code> class represents a dataframe and consists of a <code>name</code> attribute, a list of <code>RowData</code> objects in the <code>data</code> attribute, and a list of column names in the <code>columns</code> attribute. It also provides a <code>to_pandas</code> method to convert the dataframe into a Pandas DataFrame.</p> <p>The <code>Database</code> class represents a set of tables in a database. It contains a list of <code>Dataframe</code> objects in the <code>tables</code> attribute.</p>"},{"location":"examples/autodataframe/#using-the-prompt-pipeline","title":"Using the Prompt Pipeline","text":"<p>To convert a text into dataframes, we'll use the Prompt Pipeline in OpenAI Function Call. We can define a function <code>dataframe</code> that takes a text as input and returns a <code>Database</code> object.</p> <pre><code>import openai\ndef dataframe(data: str) -&gt; Database:\ncompletion = openai.ChatCompletion.create(\nmodel=\"gpt-4-0613\",\ntemperature=0.1,\nfunctions=[Database.openai_schema],\nfunction_call={\"name\": Database.openai_schema[\"name\"]},\nmessages=[\n{\n\"role\": \"system\",\n\"content\": \"\"\"Map this data into a dataframe a\n                nd correctly define the correct columns and rows\"\"\",\n},\n{\n\"role\": \"user\",\n\"content\": f\"{data}\",\n},\n],\nmax_tokens=1000,\n)\nreturn Database.from_response(completion)\n</code></pre> <p>The <code>dataframe</code> function takes a string <code>data</code> as input and creates a completion using the Prompt Pipeline. It prompts the model to map the data into a dataframe and define the correct columns and rows. The resulting completion is then converted into a <code>Database</code> object.</p>"},{"location":"examples/autodataframe/#evaluating-an-example","title":"Evaluating an Example","text":"<p>Let's evaluate the example by converting a text into dataframes using the <code>dataframe</code> function and print the resulting dataframes.</p> <pre><code>dfs = dataframe(\"\"\"My name is John and I am 25 years old. I live in \nNew York and I like to play basketball. His name is \nMike and he is 30 years old. He lives in San Francisco \nand he likes to play baseball. Sarah is 20 years old \nand she lives in Los Angeles. She likes to play tennis.\nHer name is Mary and she is 35 years old. \nShe lives in Chicago.\nOn one team 'Tigers' the captain is John and there are 12 players.\nOn the other team 'Lions' the captain is Mike and there are 10 players.\n\"\"\")\nfor df in dfs.tables:\nprint(df.name)\nprint(df.to_pandas())\n</code></pre> <p>The output will be:</p> <pre><code>People\nName  Age           City Favorite Sport\n0   John   25       New York     Basketball\n1   Mike   30  San Francisco       Baseball\n2  Sarah   20    Los Angeles         Tennis\n3   Mary   35        Chicago           None\n\nTeams\nTeam Name Captain  Number of Players\n0    Tigers    John                 12\n1     Lions    Mike                 10\n</code></pre>"},{"location":"examples/exact_citations/","title":"Example: Answering Questions with Citations","text":"<p>In this example, we'll demonstrate how to use OpenAI Function Call to ask an AI a question and get back an answer with correct citations. We'll define the necessary data structures using Pydantic and show how to retrieve the citations for each answer.</p> <p>Motivation</p> <p>When using AI models to answer questions, it's important to provide accurate and reliable information with appropriate citations. By including citations for each statement, we can ensure the information is backed by reliable sources and help readers verify the information themselves.</p>"},{"location":"examples/exact_citations/#defining-the-data-structures","title":"Defining the Data Structures","text":"<p>Let's start by defining the data structures required for this task: <code>Fact</code> and <code>QuestionAnswer</code>.</p> <p>Prompting as documentation</p> <p>Make sure to include detailed and useful docstrings and fields for your class definitions. Naming becomes very important since they are semantically meaningful in the prompt.</p> <ul> <li><code>substring_quote</code> performs better than <code>quote</code> since it suggests it should be a substring of the original content.</li> <li>Notice that there are instructions on splitting facts in the docstring which will be used by OpenAI</li> </ul> <pre><code>import openai\nfrom pydantic import Field, BaseModel\nfrom typing import List\nfrom openai_function_call import OpenAISchema\nclass Fact(BaseModel):\n\"\"\"\n    Each fact has a body and a list of sources.\n    If there are multiple facts, make sure to break them apart such that each one only uses a set of sources that are relevant to it.\n    \"\"\"\nfact: str = Field(..., description=\"Body of the sentence as part of a response\")\nsubstring_quote: List[str] = Field(\n...,\ndescription=\"Each source should be a direct quote from the context, as a substring of the original content\",\n)\ndef _get_span(self, quote, context, errs=100):\nimport regex\nminor = quote\nmajor = context\nerrs_ = 0\ns = regex.search(f\"({minor}){{e&lt;={errs_}}}\", major)\nwhile s is None and errs_ &lt;= errs:\nerrs_ += 1\ns = regex.search(f\"({minor}){{e&lt;={errs_}}}\", major)\nif s is not None:\nyield from s.spans()\ndef get_spans(self, context):\nfor quote in self.substring_quote:\nyield from self._get_span(quote, context)\nclass QuestionAnswer(OpenAISchema):\n\"\"\"\n    Class representing a question and its answer as a list of facts, where each fact should have a source.\n    Each sentence contains a body and a list of sources.\n    \"\"\"\nquestion: str = Field(..., description=\"Question that was asked\")\nanswer: List[Fact] = Field(\n...,\ndescription=\"Body of the answer, each fact should be its separate object with a body and a list of sources\",\n)\n</code></pre> <p>The <code>Fact</code> class represents a single statement in the answer. It contains a <code>fact</code> attribute for the body of the sentence and a <code>substring_quote</code> attribute for the sources, which are direct quotes from the context.</p> <p>The <code>QuestionAnswer</code> class represents a question and its answer. It consists of a <code>question</code> attribute for the question asked and a list of <code>Fact</code> objects in the <code>answer</code> attribute.</p> <p>Embedding computation</p> <p>While it's not the best idea to get too crazy with adding 100 methods to your class collocating some computation is oftentimes useful, here we implement the substring search directly with the <code>Fact</code> class.</p>"},{"location":"examples/exact_citations/#asking-ai-a-question","title":"Asking AI a Question","text":"<p>To ask the AI a question and get back an answer with citations, we can define a function <code>ask_ai</code> that takes a question and context as input and returns a <code>QuestionAnswer</code> object.</p> <p>Prompting Tip: Expert system</p> <p>Expert prompting is a great trick to get results, it can be easily done by saying things like:</p> <ul> <li>you are an world class expert that can correctly ...</li> <li>you are jeff dean give me a code review ...</li> </ul> <pre><code>def ask_ai(question: str, context: str) -&gt; QuestionAnswer:\n\"\"\"\n    Function to ask AI a question and get back an Answer object.\n    but should be updated to use the actual method for making a request to the AI.\n    Args:\n        question (str): The question to ask the AI.\n        context (str): The context for the question.\n    Returns:\n        Answer: The Answer object.\n    \"\"\"\n# Making a request to the hypothetical 'openai' module\ncompletion = openai.ChatCompletion.create(\nmodel=\"gpt-3.5-turbo-0613\",\ntemperature=0.2,\nmax_tokens=1000,\nfunctions=[QuestionAnswer.openai_schema],\nfunction_call={\"name\": QuestionAnswer.openai_schema[\"name\"]},\nmessages=[\n{\n\"role\": \"system\",\n\"content\": f\"You are a world class algorithm to answer questions with correct and exact citations. \",\n},\n{\"role\": \"user\", \"content\": f\"Answer question using the following context\"},\n{\"role\": \"user\", \"content\": f\"{context}\"},\n{\"role\": \"user\", \"content\": f\"Question: {question}\"},\n{\n\"role\": \"user\",\n\"content\": f\"Tips: Make sure to cite your sources, and use the exact words from the context.\",\n},\n],\n)\n# Creating an Answer object from the completion response\nreturn QuestionAnswer.from_response(completion)\n</code></pre> <p>The <code>ask_ai</code> function takes a string <code>question</code> and a string <code>context</code> as input. It makes a completion request to the AI model, providing the question and context as part of the prompt. The resulting completion is then converted into a <code>QuestionAnswer</code> object.</p>"},{"location":"examples/exact_citations/#evaluating-an-example","title":"Evaluating an Example","text":"<p>Let's evaluate the example by asking the AI a question and getting back an answer with citations. We'll ask the question \"What did the author do during college?\" with the given context.</p> <p>Highlight</p> <p>This just adds some color and captures the citation in <code>&lt;&gt;</code></p> <pre><code>def highlight(text, span):\nreturn (\n\"...\"\n+ text[span[0] - 50 : span[0]].replace(\"\\n\", \"\")\n+ \"\\033[91m\"\n+ \"&lt;\"\n+ text[span[0] : span[1]].replace(\"\\n\", \"\")\n+ \"&gt; \"\n+ \"\\033[0m\"\n+ text[span[1] : span[1] + 20].replace(\"\\n\", \"\")\n+ \"...\"\n)\n</code></pre> <pre><code>question = \"What did the author do during college?\"\ncontext = \"\"\"\nMy name is Jason Liu, and I grew up in Toronto Canada but I was born in China.\nI went to an arts high school but in university I studied Computational Mathematics and physics. \nAs part of coop I worked at many companies including Stitchfix, Facebook.\nI also started the Data Science club at the University of Waterloo and I was the president of the club for 2 years.\n\"\"\"\nanswer = ask_ai(question, context)\nprint(\"Question:\", question)\nprint()\nfor fact in answer.answer:\nprint(\"Statement:\", fact.fact)\nfor span in fact.get_spans(context):\nprint(\"Citation:\", highlight(context, span))\nprint()\n</code></pre> <p>In this code snippet, we print the question and iterate over each fact in the answer. For each fact, we print the statement and highlight the corresponding citation in the context using the <code>highlight</code> function.</p> <p>Here is the expected output for the example:</p> <pre><code>Question: What did the author do during college?\n\nStatement: The author studied Computational Mathematics and physics in university.\nCitation: ...s born in China.I went to an arts high school but &lt;in university I studied Computational Mathematics and physics&gt; . As part of coop I...\n\nStatement: The author started the Data Science club at the University of Waterloo and was the president of the club for 2 years.\nCitation: ...y companies including Stitchfix, Facebook.I also &lt;started the Data Science club at the University of Waterloo&gt;  and I was the presi...\nCitation: ... club at the University of Waterloo and I was the &lt;president of the club for 2 years&gt; ...\n</code></pre> <p>The output includes the question, followed by each statement in the answer with its corresponding citation highlighted in the context.</p> <p>Feel free to try this code with different questions and contexts to see how the AI responds with accurate citations.</p>"},{"location":"examples/gpt-engineer/","title":"Example: Creating Multiple Files Program","text":"<p>This example shows how to create a multiple files program based on specifications by utilizing the OpenAI Function Call. We will define the necessary data structures using Pydantic and demonstrate how to convert a specification (prompt) into multiple files.</p> <p>Motivation</p> <p>Creating multiple file programs based on specifications is a challenging and rewarding skill that can help you build complex and scalable applications.  With OpenAI Function Call, you can leverage the power of language models to generate an entire codebase and code snippets that match your specifications.</p>"},{"location":"examples/gpt-engineer/#defining-the-data-structures","title":"Defining the Data Structures","text":"<p>Let's start by defining the data structure of <code>File</code> and <code>Program</code>.</p> <pre><code>from typing import List\nfrom pydantic import Field\nfrom openai_function_call import OpenAISchema\nclass File(OpenAISchema):\n\"\"\"\n    Correctly named file with contents.\n    \"\"\"\nfile_name: str = Field(\n..., description=\"The name of the file including the extension\"\n)\nbody: str = Field(..., description=\"Correct contents of a file\")\ndef save(self):\nwith open(self.file_name, \"w\") as f:\nf.write(self.body)\nclass Program(OpenAISchema):\n\"\"\"\n    Set of files that represent a complete and correct program\n    \"\"\"\nfiles: List[File] = Field(..., description=\"List of files\")\n</code></pre> <p>The <code>File</code> class represents a single file or script, and it contains a <code>name</code> attribute and <code>body</code> for the text content of the file.  Notice that we added the <code>save</code> method to the <code>File</code> class. This method is used to writes the body of the file to disk using the name as path.</p> <p>The <code>Program</code> class represents a collection of files that form a complete and correct program.  It contains a list of <code>File</code> objects in the <code>files</code> attribute.</p>"},{"location":"examples/gpt-engineer/#calling-completions","title":"Calling Completions","text":"<p>To create the files, we will use the base <code>openai</code> API.  We can define a function that takes in a string and returns a <code>Program</code> object.</p> <pre><code>import openai\ndef develop(data: str) -&gt; Program:\ncompletion = openai.ChatCompletion.create(\nmodel=\"gpt-3.5-turbo-0613\",\ntemperature=0.1,\nfunctions=[Program.openai_schema],\nfunction_call={\"name\": Program.openai_schema[\"name\"]},\nmessages=[\n{\n\"role\": \"system\",\n\"content\": \"You are a world class programming AI capable of writing correct python scripts and modules. You will name files correct, include __init__.py files and write correct python code with correct imports.\",\n},\n{\n\"role\": \"user\",\n\"content\": data,\n},\n],\nmax_tokens=1000,\n)\nreturn Program.from_response(completion)\n</code></pre>"},{"location":"examples/gpt-engineer/#evaluating-an-example","title":"Evaluating an Example","text":"<p>Let's evaluate the example by specifying the program to create and print the resulting files.</p> <pre><code>program = develop(\n\"\"\"\n        Create a fastapi app with a readme.md file and a main.py file with \n        some basic math functions. the datamodels should use pydantic and \n        the main.py should use fastapi. the readme.md should have a title \n        and a description. The readme should contain some helpful infromation \n        and a curl example\"\"\"\n)\nfor file in program.files:\nprint(file.file_name)\nprint(\"-\")\nprint(file.body)\nprint(\"\\n\\n\\n\")\n</code></pre> <p>The output will be: <pre><code># readme.md\n-\n    # FastAPI App\n\n    This is a FastAPI app that provides some basic math functions.\n\n    ## Usage\n\n    To use this app, follow the instructions below:\n\n1. Install the required dependencies by running `pip install -r requirements.txt`.\n    2. Start the app by running `uvicorn main:app --reload`.\n    3. Open your browser and navigate to `http://localhost:8000/docs` to access the Swagger UI documentation.\n\n    ## Example\n\n    You can use the following curl command to test the `/add` endpoint:\n\n    ```bash\n$ curl -X POST -H \"Content-Type: application/json\" -d '{\"a\": 2, \"b\": 3}' http://localhost:8000/add\n    ```\n</code></pre> <pre><code># main.py\n-\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\napp = FastAPI()\nclass Numbers(BaseModel):\na: int\nb: int\n@app.post('/add')\ndef add_numbers(numbers: Numbers):\nreturn {'result': numbers.a + numbers.b}\n@app.post('/subtract')\ndef subtract_numbers(numbers: Numbers):\nreturn {'result': numbers.a - numbers.b}\n@app.post('/multiply')\ndef multiply_numbers(numbers: Numbers):\nreturn {'result': numbers.a * numbers.b}\n@app.post('/divide')\ndef divide_numbers(numbers: Numbers):\nif numbers.b == 0:\nreturn {'error': 'Cannot divide by zero'}\nreturn {'result': numbers.a / numbers.b}\n</code></pre> <pre><code># requirements.txt\n-\n    fastapi\n    uvicorn\n    pydantic\n</code></pre></p>"},{"location":"examples/gpt-engineer/#add-refactoring-capabilities","title":"Add Refactoring Capabilities","text":"<p>This second part of the example shows how OpenAI API can be used to update the multiples files previously created, based on new specifications.</p> <p>In order to do that, we'll rely on the standard unidiff format.</p> <p>This will be our definition for a change in our code base:</p> <pre><code>from pydantic import Field\nfrom openai_function_call import OpenAISchema\nclass Diff(OpenAISchema):\n\"\"\"\n    Changes that must be correctly made in a program's code repository defined as a\n    complete diff (Unified Format) file which will be used to `patch` the repository.\n    Example:\n      --- /path/to/original timestamp\n      +++ /path/to/new  timestamp\n      @@ -1,3 +1,9 @@\n      +This is an important\n      +notice! It should\n      +therefore be located at\n      +the beginning of this\n      +document!\n      +\n       This part of the\n       document has stayed the\n       same from version to\n      @@ -8,13 +14,8 @@\n       compress the size of the\n       changes.\n      -This paragraph contains\n      -text that is outdated.\n      -It will be deleted in the\n      -near future.\n      -\n       It is important to spell\n      -check this dokument. On\n      +check this document. On\n       the other hand, a\n       misspelled word isn't\n       the end of the world.\n      @@ -22,3 +23,7 @@\n       this paragraph needs to\n       be changed. Things can\n       be added after it.\n      +\n      +This paragraph contains\n      +important new additions\n      +to this document.\n    \"\"\"\ndiff: str = Field(\n...,\ndescription=(\n\"Changes in a code repository correctly represented in 'diff' format, \"\n\"correctly escaped so it could be used in a JSON\"\n),\n)\n</code></pre> <p>The <code>diff</code> class represents a diff file, with a set of changes that can be applied to our program using a tool like patch or Git.</p>"},{"location":"examples/gpt-engineer/#calling-refactor-completions","title":"Calling Refactor Completions","text":"<p>We'll define a function that will pass the program and the new specifications to the OpenAI API:</p> <pre><code>import openai\nfrom generate import Program\ndef refactor(new_requirements: str, program: Program) -&gt; Diff:\nprogram_description = \"\\n\".join(\n[f\"{code.file_name}\\n[[[\\n{code.body}\\n]]]\\n\" for code in program.files]\n)\ncompletion = openai.ChatCompletion.create(\n# model=\"gpt-3.5-turbo-0613\",\nmodel=\"gpt-4\",\ntemperature=0,\nfunctions=[Diff.openai_schema],\nfunction_call={\"name\": Diff.openai_schema[\"name\"]},\nmessages=[\n{\n\"role\": \"system\",\n\"content\": \"You are a world class programming AI capable of refactor \"\n\"existing python repositories. You will name files correct, include \"\n\"__init__.py files and write correct python code, with correct imports. \"\n\"You'll deliver your changes in valid 'diff' format so that they could \"\n\"be applied using the 'patch' command. \"\n\"Make sure you put the correct line numbers, \"\n\"and that all lines that must be changed are correctly marked.\",\n},\n{\n\"role\": \"user\",\n\"content\": new_requirements,\n},\n{\n\"role\": \"user\",\n\"content\": program_description,\n},\n],\nmax_tokens=1000,\n)\nreturn Diff.from_response(completion)\n</code></pre> <p>Notice we're using here the version <code>gpt-4</code> of the model, which is more powerful but, also, more expensive.</p>"},{"location":"examples/gpt-engineer/#creating-an-example-refactoring","title":"Creating an Example Refactoring","text":"<p>To tests these refactoring, we'll use the <code>program</code> object, generated in the first part of this example.</p> <pre><code>changes = refactor(\nnew_requirements=\"Refactor this code to use flask instead.\",\nprogram=program,\n)\nprint(changes.diff)\n</code></pre> <p>The output will be this:</p> <pre><code>--- readme.md\n+++ readme.md\n@@ -1,9 +1,9 @@\n# FastAPI App\n\n-This is a FastAPI app that provides some basic math functions.\n+This is a Flask app that provides some basic math functions.\n## Usage\n\nTo use this app, follow the instructions below:\n\n1. Install the required dependencies by running `pip install -r requirements.txt`.\n-2. Start the app by running `uvicorn main:app --reload`.\n+2. Start the app by running `flask run`.\n3. Open your browser and navigate to `http://localhost:5000/docs` to access the Swagger UI documentation.\n\n## Example\n\nTo perform a basic math operation, you can use the following curl command:\n\n```bash\n-curl -X POST -H \"Content-Type: application/json\" -d '{\"operation\": \"add\", \"operands\": [2, 3]}' http://localhost:8000/calculate\n+curl -X POST -H \"Content-Type: application/json\" -d '{\"operation\": \"add\", \"operands\": [2, 3]}' http://localhost:5000/calculate\n```\n\n--- main.py\n+++ main.py\n@@ -1,29 +1,29 @@\n-from fastapi import FastAPI\n-from pydantic import BaseModel\n+from flask import Flask, request, jsonify\n-app = FastAPI()\n+app = Flask(__name__)\n-class Operation(BaseModel):\n-    operation: str\n-    operands: list\n+@app.route('/calculate', methods=['POST'])\n+def calculate():\n+    data = request.get_json()\n+    operation = data.get('operation')\n+    operands = data.get('operands')\n-@app.post('/calculate')\n-async def calculate(operation: Operation):\n-    if operation.operation == 'add':\n-        result = sum(operation.operands)\n-    elif operation.operation == 'subtract':\n-        result = operation.operands[0] - sum(operation.operands[1:])\n-    elif operation.operation == 'multiply':\n+    if operation == 'add':\n+        result = sum(operands)\n+    elif operation == 'subtract':\n+        result = operands[0] - sum(operands[1:])\n+    elif operation == 'multiply':\n        result = 1\n-        for operand in operation.operands:\n+        for operand in operands:\n            result *= operand\n-    elif operation.operation == 'divide':\n-        result = operation.operands[0]\n-        for operand in operation.operands[1:]:\n+    elif operation == 'divide':\n+        result = operands[0]\n+        for operand in operands[1:]:\n            result /= operand\n     else:\n         result = None\n-    return {'result': result}\n+    return jsonify({'result': result})\n--- requirements.txt\n+++ requirements.txt\n@@ -1,3 +1,2 @@\n-fastapi\n-uvicorn\n-pydantic\n+flask\n+flask-cors\n</code></pre>"},{"location":"examples/planning-tasks/","title":"Example: Planning and Executing a Query Plan","text":"<p>This example demonstrates how to use the OpenAI Function Call ChatCompletion model to plan and execute a query plan in a question-answering system. By breaking down a complex question into smaller sub-questions with defined dependencies, the system can systematically gather the necessary information to answer the main question.</p> <p>Motivation</p> <p>The goal of this example is to showcase how query planning can be used to handle complex questions, facilitate iterative information gathering, automate workflows, and optimize processes. By leveraging the OpenAI Function Call model, you can design and execute a structured plan to find answers effectively.</p> <p>Use Cases:</p> <ul> <li>Complex question answering</li> <li>Iterative information gathering</li> <li>Workflow automation</li> <li>Process optimization</li> </ul> <p>With the OpenAI Function Call model, you can customize the planning process and integrate it into your specific application to meet your unique requirements.</p>"},{"location":"examples/planning-tasks/#defining-the-structures","title":"Defining the Structures","text":"<p>Let's define the necessary Pydantic models to represent the query plan and the queries.</p> <pre><code>import enum\nfrom typing import List\nfrom pydantic import Field\nfrom openai_function_call import OpenAISchema\nclass QueryType(str, enum.Enum):\n\"\"\"Enumeration representing the types of queries that can be asked to a question answer system.\"\"\"\nSINGLE_QUESTION = \"SINGLE\"\nMERGE_MULTIPLE_RESPONSES = \"MERGE_MULTIPLE_RESPONSES\"\nclass Query(OpenAISchema):\n\"\"\"Class representing a single question in a query plan.\"\"\"\nid: int = Field(..., description=\"Unique id of the query\")\nquestion: str = Field(\n...,\ndescription=\"Question asked using a question answering system\",\n)\ndependancies: List[int] = Field(\ndefault_factory=list,\ndescription=\"List of sub questions that need to be answered before asking this question\",\n)\nnode_type: QueryType = Field(\ndefault=QueryType.SINGLE_QUESTION,\ndescription=\"Type of question, either a single question or a multi-question merge\",\n)\nclass QueryPlan(OpenAISchema):\n\"\"\"Container class representing a tree of questions to ask a question answering system.\"\"\"\nquery_graph: List[Query] = Field(\n..., description=\"The query graph representing the plan\"\n)\ndef _dependencies(self, ids: List[int]) -&gt; List[Query]:\n\"\"\"Returns the dependencies of a query given their ids.\"\"\"\nreturn [q for q in self.query_graph if q.id in ids]\n</code></pre> <p>Graph Generation</p> <p>Notice that this example produces a flat list of items with dependencies that resemble a graph, while pydantic allows for recursive definitions, it's much easier and less confusing for the model to generate flat schemas rather than recursive schemas. If you want to see a recursive example, see recursive schemas</p>"},{"location":"examples/planning-tasks/#planning-a-query-plan","title":"Planning a Query Plan","text":"<p>Now, let's demonstrate how to plan and execute a query plan using the defined models and the OpenAI API.</p> <pre><code>import asyncio\nimport openai\ndef query_planner(question: str) -&gt; QueryPlan:\nPLANNING_MODEL = \"gpt-4-0613\"\nmessages = [\n{\n\"role\": \"system\",\n\"content\": \"You are a world class query planning algorithm capable ofbreaking apart questions into its dependency queries such that the answers can be used to inform the parent question. Do not answer the questions, simply provide a correct compute graph with good specific questions to ask and relevant dependencies. Before you call the function, think step-by-step to get a better understanding of the problem.\",\n},\n{\n\"role\": \"user\",\n\"content\": f\"Consider: {question}\\nGenerate the correct query plan.\",\n},\n]\ncompletion = openai.ChatCompletion.create(\nmodel=PLANNING_MODEL,\ntemperature=0,\nfunctions=[QueryPlan.openai_schema],\nfunction_call={\"name\": QueryPlan.openai_schema[\"name\"]},\nmessages=messages,\nmax_tokens=1000,\n)\nroot = QueryPlan.from_response(completion)\nreturn root\n</code></pre> <pre><code>plan = query_planner(\n    \"What is the difference in populations of Canada and the Jason's home country?\"\n)\nplan.dict()\n</code></pre> <p>No RAG</p> <p>While we build the query plan in this example, we do not propose a method to actually answer the question. You can implement your own answer function that perhaps makes a retrival and calls openai for retrival augmented generation. That step would also make use of function calls but goes beyond the scope of this example.</p> <pre><code>{'query_graph': [{'dependancies': [],\n'id': 1,\n'node_type': &lt;QueryType.SINGLE_QUESTION: 'SINGLE'&gt;,\n'question': \"Identify Jason's home country\"},\n{'dependancies': [],\n'id': 2,\n'node_type': &lt;QueryType.SINGLE_QUESTION: 'SINGLE'&gt;,\n'question': 'Find the population of Canada'},\n{'dependancies': [1],\n'id': 3,\n'node_type': &lt;QueryType.SINGLE_QUESTION: 'SINGLE'&gt;,\n'question': \"Find the population of Jason's home country\"},\n{'dependancies': [2, 3],\n'id': 4,\n'node_type': &lt;QueryType.SINGLE_QUESTION: 'SINGLE'&gt;,\n'question': 'Calculate the difference in populations between '\n\"Canada and Jason's home country\"}]} \n</code></pre> <p>In the above code, we define a <code>query_planner</code> function that takes a question as input and generates a query plan using the OpenAI API.</p>"},{"location":"examples/planning-tasks/#conclusion","title":"Conclusion","text":"<p>In this example, we demonstrated how to use the OpenAI Function Call <code>ChatCompletion</code> model to plan and execute a query plan using a question-answering system. We defined the necessary structures using Pydantic, created a query planner function. </p> <p>If you want to see multiple versions of this style of code, please visit:</p> <ol> <li>query planning example</li> <li>task planning with topo sort</li> </ol> <p>Feel free to modify the code to fit your specific use case and explore other possibilities of using the OpenAI Function Call model to plan and execute complex workflows.</p>"},{"location":"examples/recursive/","title":"Example: Parsing a Directory Tree","text":"<p>In this example, we will demonstrate how define and use a recursive class definition to convert a string representing a directory tree into a filesystem structure using OpenAI's function call api. We will define the necessary structures using Pydantic, create a function to parse the tree, and provide an example of how to use it.</p>"},{"location":"examples/recursive/#defining-the-structures","title":"Defining the Structures","text":"<p>We will use Pydantic to define the necessary data structures representing the directory tree and its nodes. We have two classes, <code>Node</code> and <code>DirectoryTree</code>, which are used to model individual nodes and the entire directory tree, respectively.</p> <p>Flat is better than nested</p> <p>While it's easier to model things as nested, returning flat items with dependencies tends to yield better results. For a flat example, check out planning tasks where we model a query plan as a dag.</p> <pre><code>import enum\nfrom typing import List\nfrom pydantic import Field\nfrom openai_function_call import OpenAISchema\nclass NodeType(str, enum.Enum):\n\"\"\"Enumeration representing the types of nodes in a filesystem.\"\"\"\nFILE = \"file\"\nFOLDER = \"folder\"\nclass Node(OpenAISchema):\n\"\"\"\n    Class representing a single node in a filesystem. Can be either a file or a folder.\n    Note that a file cannot have children, but a folder can.\n    Args:\n        name (str): The name of the node.\n        children (List[Node]): The list of child nodes (if any).\n        node_type (NodeType): The type of the node, either a file or a folder.\n    Methods:\n        print_paths: Prints the path of the node and its children.\n    \"\"\"\nname: str = Field(..., description=\"Name of the folder\")\nchildren: List[\"Node\"] = Field(\ndefault_factory=list,\ndescription=\"List of children nodes, only applicable for folders, files cannot have children\",\n)\nnode_type: NodeType = Field(\ndefault=NodeType.FILE,\ndescription=\"Either a file or folder, use the name to determine which it could be\",\n)\ndef print_paths(self, parent_path=\"\"):\n\"\"\"Prints the path of the node and its children.\"\"\"\nif self.node_type == NodeType.FOLDER:\npath = f\"{parent_path}/{self.name}\" if parent_path != \"\" else self.name\nprint(path, self.node_type)\nif self.children is not None:\nfor child in self.children:\nchild.print_paths(path)\nelse:\nprint(f\"{parent_path}/{self.name}\", self.node_type)\nclass DirectoryTree(OpenAISchema):\n\"\"\"\n    Container class representing a directory tree.\n    Args:\n        root (Node): The root node of the tree.\n    Methods:\n        print_paths: Prints the paths of the root node and its children.\n    \"\"\"\nroot: Node = Field(..., description=\"Root folder of the directory tree\")\ndef print_paths(self):\n\"\"\"Prints the paths of the root node and its children.\"\"\"\nself.root.print_paths()\nNode.update_forward_refs()\nDirectoryTree.update_forward_refs()\n</code></pre> <p>The <code>Node</code> class represents a single node in the directory tree. It has a name, a list of children nodes (applicable only to folders), and a node type (either a file or a folder). The <code>print_paths</code> method can be used to print the path of the node and its children.</p> <p>The <code>DirectoryTree</code> class represents the entire directory tree. It has a single attribute, <code>root</code>, which is the root node of the tree. The <code>print_paths</code> method can be used to print the paths of the root node and its children.</p>"},{"location":"examples/recursive/#parsing-the-tree","title":"Parsing the Tree","text":"<p>We define a function <code>parse_tree_to_filesystem</code> to convert a string representing a directory tree into a filesystem structure using OpenAI.</p> <pre><code>import openai\ndef parse_tree_to_filesystem(data: str) -&gt; DirectoryTree:\n\"\"\"\n    Convert a string representing a directory tree into a filesystem structure\n    using OpenAI's GPT-3 model.\n    Args:\n        data (str): The string to convert into a filesystem.\n    Returns:\n        DirectoryTree: The directory tree representing the filesystem.\n    \"\"\"\ncompletion = openai.ChatCompletion.create(\nmodel=\"gpt-3.5-turbo-0613\",\ntemperature=0.2,\nfunctions=[DirectoryTree.openai_schema],\nfunction_call={\"name\": DirectoryTree.openai_schema[\"name\"]},\nmessages=[\n{\n\"role\": \"system\",\n\"content\": \"You are a perfect file system parsing algorithm. You are given a string representing a directory tree. You must return the correct filesystem structure.\",\n},\n{\n\"role\": \"user\",\n\"content\": f\"Consider the data below:\\n{data} and return the correctly labeled filesystem\",\n},\n],\nmax_tokens=1000,\n)\nroot = DirectoryTree.from_response(completion)\nreturn root\n</code></pre> <p>The <code>parse_tree_to_filesystem</code> function takes a string <code>data</code> representing the directory tree and returns a <code>DirectoryTree</code> object representing the filesystem structure. It uses the OpenAI Chat API to complete the prompt and extract the directory tree.</p>"},{"location":"examples/recursive/#example-usage","title":"Example Usage","text":"<p>Let's demonstrate how to use the <code>parse_tree_to_filesystem</code></p> <p>function with an example:</p> <pre><code>root = parse_tree_to_filesystem(\n\"\"\"\n    root\n    \u251c\u2500\u2500 folder1\n    \u2502   \u251c\u2500\u2500 file1.txt\n    \u2502   \u2514\u2500\u2500 file2.txt\n    \u2514\u2500\u2500 folder2\n        \u251c\u2500\u2500 file3.txt\n        \u2514\u2500\u2500 subfolder1\n            \u2514\u2500\u2500 file4.txt\n    \"\"\"\n)\nroot.print_paths()\n</code></pre> <p>In this example, we call <code>parse_tree_to_filesystem</code> with a string representing a directory tree.</p> <p>After parsing the string into a <code>DirectoryTree</code> object, we call <code>root.print_paths()</code> to print the paths of the root node and its children. The output of this example will be:</p> <pre><code>root                               NodeType.FOLDER\nroot/folder1                       NodeType.FOLDER\nroot/folder1/file1.txt             NodeType.FILE\nroot/folder1/file2.txt             NodeType.FILE\nroot/folder2                       NodeType.FOLDER\nroot/folder2/file3.txt             NodeType.FILE\nroot/folder2/subfolder1            NodeType.FOLDER\nroot/folder2/subfolder1/file4.txt  NodeType.FILE\n</code></pre> <p>This demonstrates how to use OpenAI's GPT-3 model to parse a string representing a directory tree and obtain the correct filesystem structure.</p> <p>I hope this example helps you understand how to leverage OpenAI Function Call for parsing recursive trees. If you have any further questions, feel free to ask!</p>"},{"location":"examples/search/","title":"Example: Segmenting Search Queries","text":"<p>In this example, we will demonstrate how to leverage the <code>MultiTask</code> and <code>enum.Enum</code> features of OpenAI Function Call to segment search queries. We will define the necessary structures using Pydantic and demonstrate how segment queries into multiple sub queries and execute them in parallel with <code>asyncio</code>.</p> <p>Motivation</p> <p>Extracting a list of tasks from text is a common use case for leveraging language models. This pattern can be applied to various applications, such as virtual assistants like Siri or Alexa, where understanding user intent and breaking down requests into actionable tasks is crucial. In this example, we will demonstrate how to use OpenAI Function Call to segment search queries and execute them in parallel.</p>"},{"location":"examples/search/#defining-the-structures","title":"Defining the Structures","text":"<p>Let's model the problem as breaking down a search request into a list of search queries. We will use an enum to represent different types of searches and take advantage of Python objects to add additional query logic.</p> <pre><code>import enum\nfrom pydantic import Field\nfrom openai_function_call import OpenAISchema\nclass SearchType(str, enum.Enum):\n\"\"\"Enumeration representing the types of searches that can be performed.\"\"\"\nVIDEO = \"video\"\nEMAIL = \"email\"\nclass Search(OpenAISchema):\n\"\"\"\n    Class representing a single search query.\n    \"\"\"\ntitle: str = Field(..., description=\"Title of the request\")\nquery: str = Field(..., description=\"Query to search for relevant content\")\ntype: SearchType = Field(..., description=\"Type of search\")\nasync def execute(self):\nprint(f\"Searching for `{self.title}` with query `{self.query}` using `{self.type}`\")\n</code></pre> <p>Notice that we have added the <code>execute</code> method to the <code>Search</code> class. This method can be used to route the search query based on the enum type. You can add logic specific to each search type in the <code>execute</code> method.</p> <p>Next, let's define a class to represent multiple search queries.</p> <pre><code>from typing import List\nclass MultiSearch(OpenAISchema):\n\"Correctly segmented set of search results\"\ntasks: List[Search]\n</code></pre> <p>The <code>MultiSearch</code> class has a single attribute, <code>tasks</code>, which is a list of <code>Search</code> objects.</p> <p>This pattern is so common that we've added a helper function <code>MultiTask</code> to makes this simpler </p> <pre><code>from openai_function_call.dsl import MultiTask\nMultiSearch = MultiTask(Search)\n</code></pre>"},{"location":"examples/search/#calling-completions","title":"Calling Completions","text":"<p>To segment a search query, we will use the base openai api. We can define a function that takes a string and returns segmented search queries using the <code>MultiSearch</code> class.</p> <pre><code>import openai\ndef segment(data: str) -&gt; MultiSearch:\ncompletion = openai.ChatCompletion.create(\nmodel=\"gpt-3.5-turbo-0613\",\ntemperature=0.1,\nfunctions=[MultiSearch.openai_schema],\nfunction_call={\"name\": MultiSearch.openai_schema[\"name\"]},\nmessages=[\n{\n\"role\": \"user\",\n\"content\": f\"Consider the data below: '\\n{data}' and segment it into multiple search queries\",\n},\n],\nmax_tokens=1000,\n)\nreturn MultiSearch.from_response(completion)\n</code></pre> <p>The <code>segment</code> function takes a string <code>data</code> and creates a completion. It prompts the model to segment the data into multiple search queries and returns the result as a <code>MultiSearch</code> object.</p>"},{"location":"examples/search/#evaluating-an-example","title":"Evaluating an Example","text":"<p>Let's evaluate an example by segmenting a search query and executing the segmented queries.</p> <pre><code>import asyncio\nqueries = segment(\"Please send me the video from last week about the investment case study and also documents about your GDPR policy?\")\nasync def execute_queries(queries: Multisearch):\nawait asyncio.gather(*[q.execute() for q in queries.tasks])\nloop = asyncio.get_event_loop()\nloop.run_until_complete(execute_queries())\nloop.close()\n</code></pre> <p>In this example, we use the <code>segment</code> function to segment the search query. We then use <code>asyncio</code> to asynchronously execute the queries using the <code>execute</code> method defined in the <code>Search</code> class.</p> <p>The output will be:</p> <pre><code>Searching for `Please send me the video from last week about the investment case study` with query `Please send me the video from last week about the investment case study` using `SearchType.VIDEO`\nSearching for `also documents about your GDPR policy?` with query `also documents about your GDPR policy?` using `SearchType.EMAIL`\n</code></pre>"}]}